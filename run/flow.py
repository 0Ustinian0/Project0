# å›æµ‹æµç¨‹ï¼šé…ç½® â†’ æ•°æ® â†’ é€‰è‚¡ â†’ ç­–ç•¥ â†’ å¼•æ“ â†’ è¿è¡Œ â†’ åˆ†æ â†’ å¯è§†åŒ–
import pandas as pd
from run.imports import (
    os,
    bt,
    ConfigLoader,
    BacktestEngine,
    ModularScreenerStrategy,
    PerformanceAnalyzer,
    plot_equity_curve,
    plot_drawdown,
    plot_rolling_metrics,
    plot_monthly_heatmap,
    plot_beta_analysis,
    report_from_returns,
    get_beta_alpha_summary,
    load_benchmark_returns,
    get_sp500_tickers,
    download_data,
    download_spy,
    UNIVERSE_NAME,
    DEFAULT_DATA_DIR,
)
from engine.optimizer import (
    select_final_params,
    walk_forward_analysis,
    validate_parameter_selection,
    run_bayesian_optimization,
    compute_composite_score,
    _extract_metric,
)
from utils.logger import Logger, PREFIX_CONFIG, PREFIX_DATA, PREFIX_OPTIM, PREFIX_ENGINE, PREFIX_ANALYSIS, PREFIX_VALID

# å¤šç­–ç•¥ï¼šåç§° -> ç­–ç•¥ç±»ï¼Œä¾¿äº yaml ä¸­å†™ name: screener
STRATEGY_REGISTRY = {"screener": ModularScreenerStrategy}


def make_cerebro_factory(data, fixed_params=None):
    """è¿”å› (start, end, strategy_cls, params) -> cerebroï¼Œç”¨äº WFA / å¤šçª—å£éªŒè¯ã€‚"""
    def factory(start, end, strategy_cls, params):
        full = {**fixed_params, **params} if fixed_params else params
        data_w = {**data, 'from_date': start, 'to_date': end}
        engine = BacktestEngine(
            data=data_w,
            strategy=strategy_cls,
            strategy_params=full,
            initial_capital=data['initial_capital'],
            commission=data['commission'],
            slippage=data['slippage'],
        )
        return engine.cerebro
    return factory


def _run_single_backtest_metric(data, strategy_cls, params, metric):
    """å•æ¬¡å›æµ‹å¹¶è¿”å›æŒ‡å®šæŒ‡æ ‡ï¼ˆä¾›è´å¶æ–¯ä¼˜åŒ–è°ƒç”¨ï¼‰ã€‚"""
    engine = BacktestEngine(
        data=data,
        strategy=strategy_cls,
        strategy_params=params,
        initial_capital=data['initial_capital'],
        commission=data['commission'],
        slippage=data['slippage'],
    )
    result = engine.run()
    return _extract_metric(result, metric)


def load_config():
    """åŠ è½½é…ç½®ï¼ˆå›æµ‹å‚æ•° + ç­–ç•¥å‚æ•° + ä¼˜åŒ–/å¤šç­–ç•¥ï¼‰"""
    loader = ConfigLoader()
    bt_config = loader.get_backtest_config()
    strat_config = loader.get_strategy_config()
    data_dir = bt_config.get('data_dir', DEFAULT_DATA_DIR)
    universe = bt_config.get('universe', UNIVERSE_NAME)
    return {
        'bt': bt_config,
        'strategy': strat_config,
        'data_dir': data_dir,
        'universe': universe,
        'optimization': loader.get_optimization_config(),
        'multi_strategy': loader.get_multi_strategy_config(),
        'logging': loader.get_logging_config(),
    }


def prepare_data(config):
    """æ•°æ®å‡†å¤‡ï¼šä»é…ç½®ç”Ÿæˆå¼•æ“æ‰€éœ€çš„æ•°æ®è§„æ ¼ï¼ˆç›®å½•ã€æ—¥æœŸã€èµ„é‡‘ã€æˆæœ¬ç­‰ï¼‰"""
    bt_config = config['bt']
    data_dir = config['data_dir']
    return {
        'data_dir': data_dir,
        'from_date': bt_config['start_date'],
        'to_date': bt_config['end_date'],
        'universe_size': bt_config.get('universe_size'),
        'universe_seed': bt_config.get('universe_seed'),
        'initial_capital': bt_config['initial_capital'],
        'commission': bt_config['commission'],
        'slippage': bt_config.get('slippage', 0.0),
    }


def get_stock_universe(data):
    """ä»æ•°æ®ç›®å½•è·å–è‚¡ç¥¨æ± åˆ—è¡¨ï¼ˆä¾›å¼•æ“åŠ è½½ï¼›å®é™…é€‰è‚¡åœ¨ç­–ç•¥å†…é€æ—¥ç­›é€‰ï¼‰ã€‚universe_seed ç”¨äºå¯å¤ç°éšæœºå­é›†ã€‚"""
    data_dir = data['data_dir']
    if not os.path.isdir(data_dir):
        return []
    files = sorted([f for f in os.listdir(data_dir) if f.endswith('.csv')])
    if 'SPY.csv' in files:
        files.remove('SPY.csv')
    universe_size = data.get('universe_size')
    universe_seed = data.get('universe_seed')
    if universe_size is not None and universe_size > 0:
        if universe_seed is not None:
            import random
            rng = random.Random(universe_seed)
            files = files.copy()
            rng.shuffle(files)
        files = files[:universe_size]
    return [f.replace('.csv', '') for f in files]


def analyze_results(strategy_instance):
    """åˆ†æå›æµ‹ç»“æœï¼Œè¿”å› PerformanceAnalyzer å®ä¾‹"""
    return PerformanceAnalyzer(strategy_instance)


def _date_str(dt):
    """datetime -> YYYY-MM-DD"""
    return dt.strftime('%Y-%m-%d') if hasattr(dt, 'strftime') else str(dt)[:10]


def download_all(config):
    """æŒ‰é…ç½®ä¸‹è½½ S&P 500 å…¨é‡æ•°æ®ï¼ˆä½¿ç”¨ config ä¸­çš„ data_dir ä¸æ—¥æœŸï¼‰"""
    bt_config = config['bt']
    data_dir = config['data_dir']
    start = _date_str(bt_config.get('start_date', '2017-01-01'))
    end = _date_str(bt_config.get('end_date', '2026-02-01'))
    tickers = get_sp500_tickers()
    download_data(tickers, start_date=start, end_date=end, data_dir=data_dir)


def download_spy_only(config):
    """æŒ‰é…ç½®ä»…ä¸‹è½½ SPYï¼ˆä½¿ç”¨ config ä¸­çš„ data_dir ä¸æ—¥æœŸï¼‰"""
    bt_config = config['bt']
    data_dir = config['data_dir']
    start = _date_str(bt_config.get('start_date', '2017-01-01'))
    end = _date_str(bt_config.get('end_date', '2026-02-01'))
    download_spy(start_date=start, end_date=end, data_dir=data_dir)


def download_fundamentals(config, max_tickers=None):
    """æŒ‰ config ä¸­ data_dir æ‹‰å–å½“å‰è‚¡ç¥¨æ± çš„åŸºæœ¬é¢å¹¶ä¿å­˜ä¸º fundamentals.csvï¼ˆyfinanceï¼‰ã€‚"""
    from data.providers.fundamentals import fetch_fundamentals, get_tickers_from_data_dir
    data_dir = config.get('data_dir') or config.get('bt', {}).get('data_dir')
    if not data_dir:
        print("[!] æœªæ‰¾åˆ° data_dir é…ç½®")
        return
    tickers = get_tickers_from_data_dir(data_dir)
    if not tickers:
        print("[!] æœªåœ¨ data_dir ä¸‹æ‰¾åˆ°è‚¡ç¥¨ CSVï¼Œè¯·å…ˆè¿è¡Œ python main.py --download æˆ–æ”¾å…¥ CSV")
        return
    fetch_fundamentals(tickers, data_dir, max_tickers=max_tickers)


def run_optimization(config, data):
    """å‚æ•°ä¼˜åŒ–ï¼šgrid | walk_forward | bayesianï¼Œå¯é€‰å¤šçª—å£éªŒè¯ã€‚"""
    opt = config.get('optimization', {})
    param_grid = opt.get('param_grid', {})
    if not param_grid:
        log = Logger()
        log.warning("optimization.param_grid ä¸ºç©ºï¼Œè¯·é…ç½®è‡³å°‘ä¸€ç»„å‚æ•°åˆ—è¡¨ï¼ˆå¦‚ atr_period: [10, 14, 20]ï¼‰")
        return
    metric = opt.get('metric', 'sharperatio')
    maximize = opt.get('maximize', True)
    merged_params = {**config['strategy'], **param_grid}
    grid_only = {k: v for k, v in param_grid.items() if isinstance(v, (list, tuple)) and not isinstance(v, str)}
    fixed_params = {k: v for k, v in merged_params.items() if k not in grid_only}
    method = opt.get('method', 'grid')

    best_params, best_value, all_results = None, None, []
    log = Logger()

    if method == 'grid':
        composite_weights = opt.get('composite_weights')
        engine = BacktestEngine(
            data=data,
            strategy=None,
            initial_capital=data['initial_capital'],
            commission=data['commission'],
            slippage=data['slippage'],
        )
        best_params, best_value, all_results = engine.run_optimization(
            ModularScreenerStrategy,
            param_grid=merged_params,
            metric=metric,
            maximize=maximize,
            composite_weights=composite_weights if (metric and str(metric).lower() == 'composite') else None,
        )
        if metric and str(metric).lower() == 'composite' and composite_weights and all_results and isinstance(all_results[0][1], dict):
            all_results = compute_composite_score(all_results, composite_weights, maximize=maximize)
            best_params = all_results[0][0] if all_results else None
            best_value = all_results[0][1] if all_results else None
        log.section("å‚æ•°ä¼˜åŒ–ç»“æœ (ç½‘æ ¼æœç´¢)")
    elif method == 'walk_forward':
        train_days = int(opt.get('walk_forward_train_days', 252))
        test_days = int(opt.get('walk_forward_test_days', 63))
        cerebro_factory = make_cerebro_factory(data, fixed_params)
        best_params, best_value, wfa_results = walk_forward_analysis(
            cerebro_factory,
            ModularScreenerStrategy,
            grid_only,
            train_days,
            test_days,
            data['from_date'],
            data['to_date'],
            data.get('data_dir'),
            data.get('universe_size'),
            metric=metric,
            maximize=maximize,
            logger=log,
        )
        all_results = [(p, v) for p, v, _ in wfa_results]
        print("\nğŸ”¬ å‚æ•°ä¼˜åŒ–ç»“æœ (Walk-Forward)")
    elif method == 'bayesian':
        n_calls = int(opt.get('bayesian_n_calls', 50))
        run_backtest = lambda p: _run_single_backtest_metric(data, ModularScreenerStrategy, p, metric)
        best_params, best_value = run_bayesian_optimization(
            grid_only,
            fixed_params,
            run_backtest,
            n_calls=n_calls,
            maximize=maximize,
            logger=log,
        )
        all_results = [(best_params, best_value)] if best_params else []
        log.section("å‚æ•°ä¼˜åŒ–ç»“æœ (è´å¶æ–¯ä¼˜åŒ–)")
    else:
        log.warning(f"æœªçŸ¥ optimization.method: {method}ï¼Œä½¿ç”¨ grid")
        method = 'grid'
        engine = BacktestEngine(
            data=data,
            strategy=None,
            initial_capital=data['initial_capital'],
            commission=data['commission'],
            slippage=data['slippage'],
        )
        best_params, best_value, all_results = engine.run_optimization(
            ModularScreenerStrategy,
            param_grid=merged_params,
            metric=metric,
            maximize=maximize,
        )

    # æœ€ç»ˆå‚æ•°ï¼šgrid/walk_forward å¯å†ç» plateau/robust ç­‰é€‰æ‹©ï¼›bayesian ç›´æ¥ç”¨æœ€ä¼˜
    if method == 'bayesian' or not all_results:
        final_params, final_metric = best_params or {}, best_value
    else:
        final_method = opt.get('final_params_method', 'best')
        plateau_top_pct = float(opt.get('plateau_top_pct', 0.2))
        plateau_threshold = opt.get('plateau_threshold')  # è‹¥è®¾ç½®ï¼Œåˆ™ç”¨é˜ˆå€¼ç­›é€‰ä¼˜ç§€ç»„åˆæ›¿ä»£ top_pct
        if plateau_threshold is not None:
            plateau_threshold = float(plateau_threshold)
        robust_alpha = float(opt.get('robust_alpha', 0.7))
        robust_radius = int(opt.get('robust_radius', 1))
        n_clusters = int(opt.get('n_clusters', 3))
        grid_candidates = grid_only or None
        final_params, final_metric = select_final_params(
            all_results,
            method=final_method,
            top_pct=plateau_top_pct,
            maximize=maximize,
            grid_candidates=grid_candidates,
            robust_alpha=robust_alpha,
            robust_radius=robust_radius,
            n_clusters=n_clusters,
            plateau_threshold=plateau_threshold,
        )

    print("-" * 50)
    print(f"  ç›®æ ‡æŒ‡æ ‡: {metric} (maximize={maximize})")
    print(f"  å•ç‚¹æœ€ä¼˜: {best_params} -> {best_value}")
    print(f"  æœ€ç»ˆå‚æ•°: {final_params} -> {final_metric}")
    if all_results and len(all_results) <= 20:
        print("  å…¨éƒ¨ç»„åˆ:")
        for i, (params, val) in enumerate(all_results[:10]):
            print(f"    {i+1}. {params} -> {val}")

    if opt.get('run_final_backtest', True) and final_params:
        print("\nğŸ“Œ ä½¿ç”¨æœ€ç»ˆå‚æ•°è¿è¡Œå›æµ‹å¹¶è¾“å‡ºç»“æœ...")
        engine_final = BacktestEngine(
            data=data,
            strategy=ModularScreenerStrategy,
            strategy_params=final_params,
            initial_capital=data['initial_capital'],
            commission=data['commission'],
            slippage=data['slippage'],
        )
        result = engine_final.run()
        if result is not None:
            analyzer = PerformanceAnalyzer(result)
            report = analyzer.generate_report(log)
            visualize_results(report, data['data_dir'], logger=log)
        log.info("  æ¨èå‚æ•°ï¼ˆå¯å¤åˆ¶åˆ° config/settings.yaml çš„ strategy ä¸‹ï¼‰:")
        for k, v in sorted(final_params.items()):
            log.info(f"    {k}: {v}")

    if opt.get('run_validation', False) and final_params:
        train_days = int(opt.get('walk_forward_train_days', 252))
        test_days = int(opt.get('walk_forward_test_days', 63))
        cerebro_factory = make_cerebro_factory(data)
        report = validate_parameter_selection(
            cerebro_factory,
            ModularScreenerStrategy,
            final_params,
            train_days,
            test_days,
            data['from_date'],
            data['to_date'],
            metric=metric,
            logger=log,
        )
        print("\nğŸ“ å¤šæ—¶é—´çª—å£/æ ·æœ¬å¤–éªŒè¯")
        print("-" * 50)
        print(f"  çª—å£æ•°: {len(report['per_window'])}")
        print(f"  {metric} å‡å€¼: {report['mean']}")
        print(f"  {metric} æ ‡å‡†å·®: {report['std']}")
        if report['per_window']:
            for start, end, val in report['per_window'][:5]:
                print(f"    çª—å£ {start.date()} ~ {end.date()}: {val}")

    return final_params, final_metric, all_results


def run_multi_strategy(config, data):
    """å¤šç­–ç•¥å¹¶è¡Œï¼šå„ç­–ç•¥æŒ‰æƒé‡åˆ†é…èµ„é‡‘ç‹¬ç«‹è¿è¡Œï¼Œå†åˆå¹¶æ”¶ç›Šæ›²çº¿ã€‚"""
    multi = config.get('multi_strategy', {})
    strategies_cfg = multi.get('strategies', [])
    log = Logger()
    if not strategies_cfg:
        log.warning("multi_strategy.strategies ä¸ºç©º")
        return
    total_capital = data['initial_capital']
    returns_list = []
    weights = []
    for item in strategies_cfg:
        name = item.get('name', 'screener')
        params = item.get('params', {})
        weight = float(item.get('weight', 1.0 / len(strategies_cfg)))
        strat_cls = STRATEGY_REGISTRY.get(name, ModularScreenerStrategy)
        capital = total_capital * weight
        engine = BacktestEngine(
            data=data,
            strategy=strat_cls,
            strategy_params=params,
            initial_capital=capital,
            commission=data['commission'],
            slippage=data['slippage'],
        )
        result = engine.run()
        if result is not None and hasattr(result, 'analyzers') and hasattr(result.analyzers, 'returns'):
            ret_dict = result.analyzers.returns.get_analysis()
            ret_series = pd.Series(ret_dict)
            ret_series.index = pd.to_datetime(ret_series.index)
            returns_list.append(ret_series)
    if not returns_list:
        print("âš ï¸ æ— æœ‰æ•ˆç­–ç•¥æ”¶ç›Š")
        return
    # å¯¹é½æ—¥æœŸï¼šå¹¶é›†ï¼Œç¼ºå¤±å¡« 0
    all_index = returns_list[0].index
    for r in returns_list[1:]:
        all_index = all_index.union(r.index)
    blended = pd.Series(0.0, index=all_index)
    used_weights = weights[:len(returns_list)]
    for ret_series, w in zip(returns_list, used_weights):
        blended = blended.add(ret_series.reindex(all_index).fillna(0) * w, fill_value=0)
    report_from_returns(blended)
    visualize_results(None, data['data_dir'], rets_override=blended)


def visualize_results(report, data_dir, rets_override=None, logger=None):
    """ç”Ÿæˆå‡€å€¼æ›²çº¿ã€å›æ’¤å›¾ã€æ»šåŠ¨æŒ‡æ ‡ã€æœˆåº¦çƒ­åŠ›å›¾ã€Beta åˆ†æã€‚è‹¥ rets_override æœ‰å€¼åˆ™ç”¨å…¶ä½œä¸ºæ”¶ç›Šåºåˆ—ï¼ˆå¤šç­–ç•¥åˆå¹¶æ—¶ï¼‰ã€‚"""
    benchmark_csv = os.path.join(data_dir, 'SPY.csv')
    rets = rets_override if rets_override is not None else (report.rets if report is not None and hasattr(report, 'rets') else None)
    if rets is None or (hasattr(rets, 'empty') and rets.empty):
        if logger:
            logger.warning("æ— æ”¶ç›Šæ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–")
        return
    out = lambda msg: (logger.info(msg) if logger else print(msg))
    plot_equity_curve(rets, benchmark_csv=benchmark_csv, logger=logger)
    plot_drawdown(rets, logger=logger)
    plot_rolling_metrics(rets, window=252, save_path='rolling_metrics.png', logger=logger)
    plot_monthly_heatmap(rets, save_path='monthly_heatmap.png', logger=logger)
    plot_beta_analysis(rets, benchmark_csv=benchmark_csv, save_path='beta_analysis.png', logger=logger)
    bench_rets = load_benchmark_returns(benchmark_csv)
    beta_summary = get_beta_alpha_summary(rets, bench_rets)
    if beta_summary:
        out("\nğŸ“Š åŸºå‡†å¯¹å†² (vs SPY)")
        out("-" * 40)
        for k, v in beta_summary.items():
            out(f"  {k}: {v}")


def main(force_optimize=False, force_multi_strategy=False):
    # 1. åˆå§‹åŒ–é…ç½®
    config = load_config()
    log_cfg = config.get('logging') or {}
    log = Logger(
        log_dir=log_cfg.get('log_dir', 'logs'),
        file_name=log_cfg.get('file_name'),
        retain_count=log_cfg.get('retain_count', 10),
        quiet_console_init=log_cfg.get('quiet_console_init', False),
    )
    log.info(f"{PREFIX_CONFIG} é…ç½®å·²åŠ è½½ | æ•°æ®æº: {config['universe']} ({config['data_dir']})")

    # 2. æ•°æ®å‡†å¤‡
    data = prepare_data(config)

    # 3. ç­›é€‰è‚¡ç¥¨æ± ï¼ˆè·å–å¾…åŠ è½½æ ‡çš„åˆ—è¡¨ï¼›ç­–ç•¥å†… Screener é€æ—¥ç­›é€‰ï¼‰
    stock_universe = get_stock_universe(data)
    log.info(f"{PREFIX_DATA} æ•°æ®ç›®å½•ä¸‹å…± {len(stock_universe)} åªæ ‡çš„å¯åŠ è½½")

    if force_optimize or config.get('optimization', {}).get('enabled'):
        run_optimization(config, data)
        return

    if force_multi_strategy or config.get('multi_strategy', {}).get('enabled'):
        run_multi_strategy(config, data)
        return

    # 4. å•ç­–ç•¥å›æµ‹
    strategy = ModularScreenerStrategy
    params = config['strategy']
    log.info(f"{PREFIX_CONFIG} ç­–ç•¥å‚æ•°: {params}")

    engine = BacktestEngine(
        data=data,
        strategy=strategy,
        strategy_params=params,
        initial_capital=data['initial_capital'],
        commission=data['commission'],
        slippage=data['slippage'],
    )
    results = engine.run()
    analyzer = PerformanceAnalyzer(results)
    report = analyzer.generate_report(log)
    visualize_results(report, data['data_dir'], logger=log)
