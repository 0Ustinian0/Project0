"""æ•°æ®åŠ è½½ï¼šä»Ž CSV ç›®å½•åŠ è½½å¹¶ç”Ÿæˆ Backtrader feeds"""
import os
import pandas as pd
import backtrader as bt


def add_csv_feed(cerebro, filepath, name, start, end, logger=None):
    """
    è¯»å–å•åªè‚¡ç¥¨ CSVï¼Œè½¬æ¢ä¸º PandasData å¹¶åŠ å…¥ cerebroã€‚
    å…¼å®¹æ ¼å¼ï¼šskiprows=3, åˆ—ä¸º Date, Close, High, Low, Open, Volumeã€‚
    """
    try:
        df = pd.read_csv(
            filepath,
            skiprows=3,
            header=None,
            names=['Date', 'Close', 'High', 'Low', 'Open', 'Volume'],
            parse_dates=[0],
            index_col=0
        )
        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        df = df.dropna(subset=['Open', 'High', 'Low', 'Close', 'Volume'])
        df = df[(df.index >= pd.Timestamp(start)) & (df.index <= pd.Timestamp(end))]
        if len(df) == 0:
            return False
        data = bt.feeds.PandasData(
            dataname=df,
            name=name,
            fromdate=start,
            todate=end,
            open='Open', high='High', low='Low', close='Close', volume='Volume',
            openinterest=None
        )
        cerebro.adddata(data)
        return True
    except Exception as e:
        if logger:
            logger.warning(f"åŠ è½½ {name} å¤±è´¥: {e}")
        return False


def load_data_into_cerebro(cerebro, data_dir, from_date, to_date, universe_size=None, logger=None):
    """
    å°† data_dir ä¸‹çš„ CSV åŠ è½½åˆ° cerebroï¼šSPY ä½œä¸º data0ï¼Œå…¶ä½™æŒ‰ universe_size é™åˆ¶æ•°é‡ã€‚
    """
    if not os.path.exists(data_dir):
        raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
    all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
    if 'SPY.csv' in all_files:
        add_csv_feed(cerebro, os.path.join(data_dir, 'SPY.csv'), 'SPY', from_date, to_date, logger)
        all_files.remove('SPY.csv')
    else:
        if logger:
            logger.warning("æœªæ‰¾åˆ° SPY.csvï¼Œå¤§ç›˜é£ŽæŽ§å¯èƒ½å¤±æ•ˆ")
    target_files = all_files[:universe_size] if universe_size else all_files
    for filename in target_files:
        ticker = filename.split('.')[0]
        filepath = os.path.join(data_dir, filename)
        add_csv_feed(cerebro, filepath, ticker, from_date, to_date, logger)
    if logger:
        logger.info(f"ðŸ“Š [æ•°æ®] è£…è½½å®Œæˆã€‚æ€»è®¡: {len(cerebro.datas)} åª (å«SPY)")
    return len(cerebro.datas)
