"""
æ•°æ®ä¸‹è½½ï¼šS&P 500 å…¨é‡ / ä»… SPY
ç”¨æ³•:
  å…¨é‡: python -m data.providers.manager
  ä»…SPY: python -m data.providers.manager --spy-only
"""
import os
import io
import argparse
import yfinance as yf
import pandas as pd
import requests

# ä¸ main ä¸€è‡´ï¼šS&P 500 æ•°æ®ç›®å½•
DATA_DIR = os.path.join('data', 'SP500')


def get_sp500_tickers():
    """ä»ç»´åŸºç™¾ç§‘è·å– S&P 500 æˆåˆ†è‚¡åˆ—è¡¨"""
    print("æ­£åœ¨è·å– S&P 500 æˆåˆ†è‚¡åˆ—è¡¨...")
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (Chrome/91.0.4472.124) Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        tables = pd.read_html(io.StringIO(response.text))
        tickers = tables[0]['Symbol'].tolist()
        tickers = [t.replace('.', '-') for t in tickers]
        print(f"âœ… è·å–æˆåŠŸï¼Œå…± {len(tickers)} åªè‚¡ç¥¨ã€‚")
        return tickers
    except Exception as e:
        print(f"âŒ è·å–åˆ—è¡¨å¤±è´¥: {e}")
        print("âš ï¸ å°†ä½¿ç”¨é»˜è®¤å¤‡é€‰åˆ—è¡¨...")
        return ['NVDA', 'AMD', 'TSLA', 'AAPL', 'MSFT', 'AMZN', 'GOOG', 'META', 'NFLX', 'PLTR', 'COIN', 'MARA']


def download_spy(start_date='2017-01-01', end_date='2026-02-01', data_dir=None):
    """ä»…ä¸‹è½½ SPY åˆ°æŒ‡å®šç›®å½•ï¼ˆé»˜è®¤ data/SP500/ï¼‰"""
    target_dir = data_dir or DATA_DIR
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)
    print("æ­£åœ¨å•ç‹¬ä¸‹è½½ SPY æ•°æ®...")
    df = yf.download('SPY', start=start_date, end=end_date, auto_adjust=True, progress=False)
    if df.empty:
        print("âŒ SPY ä¸‹è½½å¤±è´¥ï¼Œæ— æ•°æ®ã€‚")
        return
    out_path = os.path.join(target_dir, 'SPY.csv')
    df_formatted = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy()
    df_formatted.reset_index(inplace=True)
    df_formatted.to_csv(out_path, index=False, header=True)
    print(f"âœ… SPY.csv å·²ä¿å­˜è‡³ {out_path}")


def download_data(tickers, start_date='2017-01-01', end_date='2026-01-01', data_dir=None):
    """æ‰¹é‡ä¸‹è½½æ•°æ®å¹¶ä¿å­˜ä¸º CSV"""
    target_dir = data_dir or DATA_DIR
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)
    print(f"å¼€å§‹ä¸‹è½½æ•°æ® ({start_date} è‡³ {end_date})...")
    print(f"ç›®æ ‡è‚¡ç¥¨æ•°: {len(tickers)} (å…¨é‡ä¸‹è½½å¯èƒ½éœ€è¦ 5â€“10 åˆ†é’Ÿ)")
    data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker', auto_adjust=True, threads=True, progress=False)
    success_count = 0
    if len(tickers) == 1:
        ticker = tickers[0]
        try:
            if not data.empty:
                df_formatted = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()
                df_formatted.reset_index(inplace=True)
                df_formatted.to_csv(os.path.join(target_dir, f"{ticker}.csv"), index=False, header=True)
                success_count += 1
        except Exception:
            pass
    else:
        for ticker in tickers:
            try:
                df = data[ticker].dropna()
                if len(df) < 200:
                    continue
                df_formatted = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy()
                df_formatted.reset_index(inplace=True)
                df_formatted.to_csv(os.path.join(target_dir, f"{ticker}.csv"), index=False, header=True)
                success_count += 1
            except Exception as e:
                print(f"âš ï¸ å¤„ç† {ticker} å¤±è´¥: {e}")
    print(f"ğŸ‰ ä¸‹è½½å®Œæˆï¼æˆåŠŸä¿å­˜ {success_count} åªè‚¡ç¥¨æ•°æ®åˆ° '{target_dir}/'")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ä¸‹è½½ S&P 500 æˆ–ä»… SPY æ•°æ®')
    parser.add_argument('--spy-only', action='store_true', help='ä»…ä¸‹è½½ SPY')
    parser.add_argument('--start', default='2017-01-01', help='èµ·å§‹æ—¥æœŸ')
    parser.add_argument('--end', default='2026-02-01', help='ç»“æŸæ—¥æœŸ')
    args = parser.parse_args()
    if args.spy_only:
        download_spy(start_date=args.start, end_date=args.end)
    else:
        tickers = get_sp500_tickers()
        download_data(tickers, start_date=args.start, end_date=args.end)
